\documentclass[a4paper,12pt,twoside]{ThesisStyle}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{thesis-style}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{tabularx}
\usepackage{geometry}
\usepackage{rotating}
\usepackage{appendix}
\usepackage{soul}  % BEA \st{}


\geometry{a4paper, margin=1in}

\captionsetup{font=small}


\begin{document}

\frontmatter

\pagenumbering{gobble}

\thispagestyle{empty}
\begin{table}[htb]
\centering
\begin{Large}
\resizebox{\textwidth}{!}{\begin{tabular}{ | l |}
 \hline
 \\
\includegraphics[scale=0.9]{imatges/logo_eps.png} \\[0.7cm]
\centerline{\hl{Master's Thesis}}\\[1cm]
\hline
\\
Study: Master in Data Science and Machine Learning\\[0.7cm]
\hline
\\
Title: CNV Detection using Machine Learning in Targeted Sequencing\\[0.7cm]
\hline
\\
Document: Memory\\[0.7cm]
\hline
\\
Student: Oriol Canal Pujol\\[0.7cm]
\hline
\\
Tutor: Maria Beatriz Lopez Ibañez\\
Department: Grup de Recerca en Enginyeria de Control i Sistemes Intel·ligents (EXIT)\\
Àrea: ENGINYERIA DE SISTEMES I AUTOMÀTICA\\
Cotutor: Bernat del Olmo Cabestré \\
\hl{Institution: Institut d’Investigació Biomèdica de Girona (IDIBGI)}\\ [0.7cm]
\hline
\\
Call: September 2024\\[0.7cm]
\hline

\end{tabular}}
\end{Large}
\end{table}

\newpage
\hypersetup{pageanchor=false}
\begin{titlepage}

% Upper part of the page
\includegraphics[scale=0.9]{imatges/logo_eps.png} \\[1cm]
\begin{center}
\textsc{\Large Master\hl{'s} Thesis} \\[1cm]

% Title
\begin{spacing}{2}
\HRule \\
\textbf{\Huge CNV Detection using Machine Learning in Targeted Sequencing} \\
\HRule \\[0.5cm]
\end{spacing}

% Author and supervisor and other data
{
\large
\emph{Author:} \\
Oriol \textsc{Canal Pujol} \\[1cm]
September 2024 \\[1cm]
Master in Data Science and Machine Learning \\[1cm]
\emph{Tutors:} \\
Beatriz \textsc{Lopez Ibañez} \\
Bernat \textsc{del Olmo Cabestré} \\
}

\end{center}
\end{titlepage}
\hypersetup{pageanchor=true}

\titlepage

%\dominitoc


\pagenumbering{roman}

\chapter*{Resum}
%\label{cap:resum}



\chapter*{Agraïments}
%\label{cap:agraiments}

Per començar vull agrair molt especialment a \ldots


\input{acronyms}

\tableofcontents

\listoffigures

\listoftables


\mainmatter

\chapter{Introduction}
\label{cap:intro}




In this chapter the main motivations for this work are described, alongside with it’s
main contributions.

\section{Motivation}
The rapid advancements in genomic technologies have opened up new frontiers in the study of genetic diseases and personalized medicine. The ability to decode the human genome with unprecedented speed and accuracy has transformed our understanding of genetic variations and their role in health and disease. This thesis aims to explore these advancements, focusing on the powerful capabilities of Next Generation Sequencing (NGS) and its application in detecting genetic variations that can influence disease outcomes.

Understanding genetic variations is crucial for diagnosing and treating various medical conditions. Among these variations, Copy Number Variants (CNVs) play a significant role due to their potential impact on gene dosage and expression. Despite their importance, CNVs present unique challenges in detection and interpretation, particularly in targeted gene panels used for studying specific conditions such as sudden cardiac death. Addressing these challenges requires sophisticated analytical approaches and robust datasets.

\textcolor{blue}{ALL THE REMAINDER OF WHAT WAS WRITTEN IN THIS CHAPTER HAS BEEN MOVED TO PRELIMINARS.}


CNVs are a major cause of several genetic disorders, making their detection an essential component of genetic analysis pipelines. 
Current methods for detecting CNVs from targeted-sequencing data are limited by high false positive rates and low concordance because of the inherent biases of individual algorithms. 

\section{Objectives}
In this project, we introduce Targeted-CNV-Learner, a machine learning software  designed to enhance CNV detection by integrating outputs from multiple CNV detection algorithms. The software learns to accurately identify true CNVs by leveraging both caller-specific and genomic features derived from a set of in silico CNVs inserted into the samples. The primary objective of this project is to develop a model that improves the precision and selectivity of existing standalone algorithms, providing a more reliable approach for CNV detection in clinical diagnostics. 

%that integrates \st{calls from} multiple CNV detection algorithms and learns to accurately identify true CNVs using caller-specific and genomic features from a set of in silico CNVs inserted in the samples. The primary objective of this project is to develop a model that enhances the precision and selectivity of various standalone algorithms, offering an improved approach for CNV detection in clinical diagnostics.

%Our primary goal is to identify all possible CNVs, even if this results in a higher rate of false positives \hl{provided by existing algorithms (REVISA) (see Figure XX)}.

\begin{wrapfigure}{r}{0.55\textwidth}    \centering
    \includegraphics[width=0.55\textwidth]{imatges/CNV_call_process.png}\caption{\label{fig:cnv_validation_process}Validation process over the calls made by the CNV detection pipeline.}
\end{wrapfigure}

A crucial aspect of CNV detection in clinical diagnostics is the need for orthogonal validation techniques to confirm CNV calls. Orthogonal methods, such as MLPA, are essential for validating CNVs as they offer independent confirmation of results obtained from computational models. MLPA is a wet lab technique that uses a different methodology to detect CNVs, thereby reducing the risk of false positives that might arise from algorithmic predictions alone. However, this validation layer is associated with significant costs and logistical challenges.

To address these challenges, our model aims to enhance the accuracy of CNV predictions. By integrating CNV calls from various algorithms, Targeted-CNV-Learner seeks to minimize false positives, which in turn reduces the need for costly orthogonal validation (Figure \ref{fig:cnv_validation_process}). Fewer false positives translate to a reduced demand for additional validation, thereby decreasing both the cost and complexity of the validation process. By maximizing recall, our approach ensures that the CNVs flagged by the model are more likely to be genuine, optimizing the use of orthogonal techniques and making th eoverall validation process more efficient and cost-effective.

To validate the effectiveness of Targeted-CNV-Learner, we evaluate its performance using data from 400 samples derived from the Sudden Cardiac Death genetic panel (SUDD147), developed by the Unit of Molecular Diagnostic and Personalized Medicine (UDMMP) at Hospital Josep Trueta. This dataset will be used to train, test and assess the model's ability to improve CNV detection accuracy and reduce the reliance on extensive orthogonal validation. 
 
 %An essential aspect of this approach is the need for orthogonal validation techniques to confirm the CNV calls. Orthogonal methods, such as MLPA (ficar-ho a acrònims), are critical for validating CNVs because they provide an independent confirmation of results obtained from computational methods. MLPA is a wet lab technique that is particularly valuable because it uses a different methodology to detect copy number variations, thus reducing the risk of false positives that might arise from algorithmic predictions alone. Although this additional layer of validation ensures the accuracy of CNV detection, it also entails significant costs and logistical challanges.
 
 %To mitigate these challanges, our model focuses on enhancing the accuracy of CNV predictions. By integrating the CNV calls from different algorithms in our model, we aim to create a model that helps to identify false positive calls. This reduction has a direct impact on the resources required for orthogonal validation: fewer false positives means that less validation is needed, thereby lowering both the cost and the complexity of the validation process. By maximizing recall, our approach ensures that the CNVs flagged as positive are more likely to be genuine, thus optimizing the use of orthogonal techniques and making the overall validation process more efficient and cost-effective.
 
 
 %To demonstrate the effectiveness of Targeted-CNV-Learner, we will evaluate its performance using data from 400 samples obtained from a Sudden Cardiac Death genetic panel (SUDD 147) developed by the Unit of Molecular Diagnostic and Personalized Medicine (UDMMP) at Hospital Josep Trueta. This dataset will be used to train, test, and assess the model's ability to improve CNV detection accuracy and reduce the need for extensive orthogonal validation.
 
 %This reimproving the precision of our CNV calls, we aim to reduce the number of false positives flagged by the model., This strategy is justified because \hl{an ortogonal validation technique is required to validate CNVs. Such technique consists on....test in wed labs - alguna cosa similar que clarifiqui que és una tècnica ortogonal, posant la ref. They are costly. Therefore } to confirm the presence of CNVs identified by our model \hl{could minimize this cost. Figure } \ref{fig:cnv_validation_process} \hl{Shows the purpose of use of our method in the clinical practice}.  False positives generated by the model will undergo further validation, minimizing the risk of missing true CNVs during the orthogonal validation process \hl{REVISA, segons el dibuix, no sembla que diguis que es fa una validacio addicional sino que es descarten}. Therefore, maximizing recall \hl{(identification of CNVs)} is crucial to ensure that as many potential CNVs as possible are flagged for further validation.


%To demonstrate its effectiveness, we \st{will} run the different algorithms on 400 samples from a Sudden Cardiac Death genetic panel (SUDD 147) developed by the Unit of Molecular Diagnostic and Personalized Medicine (UDMMP) at Hospital Josep Trueta. Subsequently, we will use this data to train, test, and evaluate the model's performance.

%\textcolor{blue}{REMAINING DETAILS OF THE OBJECTIVES CANNOT BE DESCRIBED HERE WITHOUT READING THE PRELIMINARS CHAPTERS. MOVE TO METHODOLOGY. }

\section{Thesis structure}
\hl{Please complete}

\chapter{Preliminaries}

The aim of this chapter is to present the theoretical background required for understanding the project contributions. 

\section{Terminology}
This section introduces essential \st{Next Generation Sequencing (}NGS\st{)} terminology to facilitate understanding of the project, \hl{and some basics about machine learning (ML). }

\subsection{Terminology on NGS}
\begin{itemize}
    \item  \textbf{Exon}:  An exon is a segment of a gene that codes for a portion of the final mature mRNA, produced after the removal of introns (non-coding regions) through RNA splicing. Exons contain the information that directs protein synthesis and play a critical role in gene expression and regulation.
    \hl{Completa amb la imatge de la slide "gene to protein"}
    \item \textbf{Panel}:  refers to a specific set of genes or genomic regions selected for sequencing and analysis. Panels are designed to focus on regions of interest that are relevant to particular research or clinical questions. In this project, we will be using a panel called SUDD 147, which contains 147 genes related to Sudden Cardiac Death.
    \hl{COMPLETA amb la figura de la slide que el descriu. }
    \item  \textbf{Mappability}: Mappability in targeted next-generation sequencing refers to the ability to accurately align sequencing reads to a reference genome, ensuring that each read can be uniquely and correctly mapped to a specific genomic location. High mappability regions are essential for accurate variant detection and minimizing false positives. It is influenced by factors such as the sequence complexity, repeat regions, and the quality of the reference genome.

    
    \item  \textbf{GC content}: GC content refers to the percentage of guanine (G) and cytosine (C) bases in a DNA sequence. In targeted NGS, regions with high or low GC content can affect sequencing efficiency and accuracy, potentially leading to biases in read coverage and challenges in variant detection.
    \item  \textbf{Autosomal chromosome}: An autosomal chromosome is any chromosome that is not a sex chromosome. In humans, there are 22 pairs of autosomal chromosomes, which carry the bulk of genetic information influencing most inherited traits and conditions. These chromosomes are inherited equally from both parents and are present in both males and females.
    \item  \textbf{CNV breakpoint}: A CNV breakpoint is the precise genomic location where a segment of DNA has been duplicated or deleted, leading to variations in the number of copies of that segment within the genome. These breakpoints mark the boundaries of the CNV event. 
    \item  \textbf{Read Depth}: Read depth refers to the number of times a specific nucleotide in a genome is sequenced during a sequencing experiment. Higher read depth increases the accuracy of detecting genetic variants and ensures reliable coverage of the genome. It is a critical factor in various genomic analyses, including variant calling and CNV detection.
    \item \hl{CNV detection algorithm}
    \item \hl{call of a CNV detection algorithm}
\end{itemize}

\begin{figure}[htb]
\centering
\includegraphics[width=12 cm]{imatges/ngs_notation.png}
\caption[Illustration of the concepts of exons, introns, read depth, and targeted sequencing in the context of Next-Generation Sequencing (NGS)]{\label{fig:ngs_notation} \hl{Illustration of} the concepts of exons, introns, read depth, and targeted sequencing in the context of Next-Generation Sequencing (NGS) \hl{(From REF)}. Gene 1 consists of two exons (exon 1 and exon 2) and one intron (intron 1), along with an intragenic region between Gene 1 and Gene 2. The read depth is indicated by the amount of stacked horizontal lines. For Gene 1, exon 1 has a read depth of 11X, and exon 2 has a read depth of 7X, demonstrating varying coverage across the gene. In contrast, Gene 2 is not targeted by the panel, resulting in no coverage for this gene. \hl{ON ES CITA AQUESTA FIGURA. COMPROVA QUE TOTES LES FIGURES I TAULES ESTIGUIN CITADES }}
\end{figure}

\subsection{Terminology on ML}
\st{Now, let's introduce }
Some essential machine learning (ML) terminology to facilitate understanding of the project \hl{are the following:}.

\begin{itemize}
    \item  \textbf{Model}: A model in machine learning is a mathematical representation of a real-world process, built using algorithms to find patterns in data. It makes predictions or decisions based on input data, learning from training data to generalize to new, unseen data.
    \item \textbf{Decision Tree}: A decision tree is a machine learning model that splits data into branches based on feature values to make predictions. Each internal node represents a decision on a feature, each branch represents an outcome of the decision, and each leaf node represents a final prediction or class.
    \item \textbf{Random Forest}: A random forest is an ensemble machine learning algorithm that combines multiple decision trees to improve prediction accuracy and robustness. Each tree in the forest is built on a random subset of the data and features, and the final output is determined by averaging the predictions (regression) or taking a majority vote (classification). This method reduces overfitting and enhances model generalization.
    \item \textbf{Overfitting}: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and specific patterns that do not generalize to new data. This results in high accuracy on the training set but poor performance on unseen data. 
    


\end{itemize}
\section{Background}
This section begins by delving into the fundamentals and transformative impact of NGS technology. It then examines the challenges associated with CNV detection and the innovative solutions developed to overcome these hurdles.
\subsection{Next Generation Sequencing}
\textcolor{blue}{Pots introduir d'alguna manera les imatges corresponents a les slides 2 - NGS sequencing  }

In recent years, advancements in technology have significantly enhanced our ability to study the genetic material of living organisms. One of the most groundbreaking developments in this field is Next Generation Sequencing (NGS). NGS is a transformative genomic sequencing technology that enables researchers and clinicians to rapidly and cost-effectively analyze vast amounts of genetic data. This advanced method facilitates the identification of disease-causing pathogens and cancer-associated mutations in patient genomes with enhanced speed and precision. By significantly reducing the time and cost associated with genetic analysis, NGS has revolutionized the fields of genomics and personalized medicine, providing critical insights into the genetic underpinnings of various diseases.

NGS technology represents a significant advancement over traditional sequencing methods, such as Sanger sequencing, by allowing for high-throughput sequencing that can cover entire genomes or specific genomic regions of interest. This high-throughput capability is particularly beneficial for comprehensive studies of genetic variation. Single Nucleotide Polymorphisms (SNPs), which are single nucleotide differences in the DNA sequence, and insertions and deletions (indels), small additions or losses of DNA bases, are common types of genetic variations detected through NGS. SNPs occur frequently and contribute to genetic diversity among individuals, while indels can affect gene function depending on their location within the genome.

Another important type of genetic variation detected by NGS is Copy Number Variants (CNVs), which involve duplications or deletions of large genomic segments. CNVs can range in size from thousands to millions of base pairs and are known to influence gene dosage and expression levels. These structural variations are implicated in various diseases, including developmental disorders and cancers, making them crucial targets for genetic research and clinical diagnostics.

The ability to sequence multiple samples simultaneously with high accuracy makes NGS a powerful tool in both research and clinical settings. It enables comprehensive studies of genetic variation across populations and facilitates the identification of disease-causing mutations with unprecedented speed and precision. As NGS technology continues to evolve, its impact on genomics and personalized medicine is expected to grow, further enhancing our understanding of genetic mechanisms underlying health and disease.

\subsection{Targeted Sequencing}

Targeted sequencing is a specialized approach in genomic analysis that enables researchers to selectively sequence specific regions of interest within the genome. Unlike whole-genome sequencing, which sequences the entire genome indiscriminately, targeted sequencing focuses on predefined genomic regions. This method is particularly advantageous in studies where a comprehensive analysis of the entire genome is unnecessary or cost-prohibitive.
\begin{figure}[htb]
\includegraphics[width=15 cm]{imatges/targeted_sequencing.jpg}
\caption{\label{fig:logo} Targeted sequencing focus on achieving high coverage (blue bars) over a specific regions of interest (targeted region) in the genome for accurate detection of genetic variants.}
\end{figure}


Targeted sequencing involves several key steps:

\begin{itemize}
    \item \textbf{Genomic DNA Library Preparation}: The initial step in targeted sequencing is the preparation of a genomic DNA library. This involves extracting genomic DNA from a sample, such as blood or tissue, and fragmenting it into smaller pieces using mechanical or enzymatic methods. The fragmented DNA ends are then modified to ensure they are ready for sequencing, and short synthetic sequences called adapters are attached to both ends of each fragment. In some cases, the library is amplified using polymerase chain reaction (PCR) to increase the quantity of DNA fragments.
    
    \item \textbf{Targeted DNA Enrichment}: Once the DNA library is prepared, the next step is to enrich for the regions of interest. This is achieved through hybridization capture, where probes—short, single-stranded DNA or RNA molecules that are complementary to the target regions—are used. These probes bind to their complementary sequences within the DNA library. The probe-bound DNA fragments are then captured using magnetic beads or another separation method, while non-target sequences are washed away. Finally, the target DNA fragments are released from the beads, resulting in an enriched library that predominantly contains the regions of interest.

    \item \textbf{Paired-End Sequencing}: The enriched DNA library is then subjected to paired-end sequencing, which involves sequencing both ends of each DNA fragment using a sequencing platform, such as Illumina. This platform reads the nucleotide sequence from each end of the DNA fragment, creating two reads per fragment. This paired-end approach improves the accuracy of alignment and variant detection.
    
    \item \textbf{Alignment to the Human Reference Genome}: The sequencing reads are mapped to a reference genome, such as GRCh38, to determine their origin within the genome. Bioinformatics tools like BWA or Bowtie align the paired-end reads to the reference genome, and the alignment information is stored in SAM (Sequence Alignment/Map) or BAM (Binary Alignment/Map) files, indicating the position of each read in the reference genome.
    
    \item \textbf{Variant Detection and Annotation}: Finally, the aligned reads are analyzed to identify genetic variants, which are differences between the sequenced sample and the reference genome. Bioinformatics tools such as GATK or FreeBayes detect single nucleotide polymorphisms (SNPs), insertions, deletions (indels), and copy number variants (CNVs). Quality filters are applied to remove low-confidence variants, and annotation tools like ANNOVAR, SnpEff or Variant Effect Predictor provide information on the genomic context and potential significance of the variants.

\end{itemize}
By following these steps, targeted sequencing provides a focused and efficient method for analyzing specific genomic regions, facilitating the identification of genetic variations associated with diseases and advancing our understanding of genetic underpinnings in various biological processes.
\begin{figure}[htb]
\centering
\includegraphics[width=15 cm]{imatges/DNA_sequencing.png}
\caption{\label{fig:logo} Illustrates the comprehensive workflow of genomic DNA targeted sequencing.}
\end{figure}

\subsection{Copy number variations}


\begin{wrapfigure}{r}{0.5\textwidth} % 'r' for right, '0.5\textwidth' for the width of the figure environment
    \centering
    \includegraphics[width=0.48\textwidth]{imatges/CNV.jpg} % Adjust the width as necessary
    \caption{\label{fig:CNV} Illustrates the comprehensive workflow of genomic DNA targeted sequencing.}
\end{wrapfigure}

Copy Number Variations (CNVs) are a form of structural genetic variation characterized by the duplication or deletion of large segments of DNA, ranging from thousands to millions of base pairs (Figure~\ref{fig:CNV}). These variations can significantly impact gene dosage and expression levels, influencing phenotypic diversity and contributing to various disease processes. CNVs are particularly notable for their role in complex diseases, such as neurodevelopmental disorders, psychiatric conditions, radiological disorders and various cancers.
\\\\\\
CNVs can affect the patients in several ways:
\begin{itemize}

    \item \textbf{Gene dosage}: Changes in the number of gene copies can lead to overexpression or underexpression of genes, affecting cellular function and potentially leading to disease. For instance, duplications of oncogenes can drive cancer progression, while deletions of tumor suppressor genes can remove critical regulatory mechanisms that prevent uncontrolled cell growth.
    \item \textbf{Gene disruption}: CNVs can interrupt the coding sequence of genes, potentially leading to truncated or nonfunctional proteins. This can result in loss-of-function effects that disrupt normal biological processes.
    \item \textbf{Regulatory elements}: CNVs can encompass regulatory regions such as promoters or enhancers, altering gene expression patterns and contributing to phenotypic variation and disease susceptibility.
\end{itemize}

% \begin{figure}[htb]
% \centering
% \includegraphics[width=8 cm]{imatges/CNV.jpg}
% \caption{\label{fig:logo} Deletion and duplication of the chromosomal region  C}
% \end{figure}
\subsection{Detection of CNVs} \label{sec:back-detectionCNV}
Next-generation sequencing (NGS) is an outstanding technology for detecting single-nucleotide variants and small deletions and insertions in genetic testing for Mendelian conditions. However, detecting large rearrangements, such as copy-number variants (CNVs), from NGS data remains challenging due to issues intrinsic to the technology, including short read lengths and GC-content bias. Despite these challenges, it is well recognized that germline CNVs are the genetic cause of several hereditary diseases, making their analysis a necessary step in a comprehensive genetic diagnostics strategy.

Traditionally, the gold standards for CNV detection in genetic diagnostics have been multiplex ligation-dependent probe amplification (MLPA) and array comparative genomic hybridization (aCGH). While both methods are highly reliable, they are also time-consuming and costly, often leading to the testing of only a subset of genes and excluding others from the analysis, particularly in single-gene approaches. Thus, the ability to use NGS data as a first screening step for CNVs would significantly decrease the number of MLPA/aCGH tests required and conserve valuable resources.

\hl{Aquí no hauries de mencioar que els algorismes de detecció de CNV utilitzen el read-depth per a la detecció de CNVs - explicant el que hi ha a les slides corresponent.? (i incorporant les imatges?}

\subsection{Challanges in detecting CNVs in targeted sequencing}
Numerous tools have been developed for CNV detection from NGS data. Most of these tools were originally designed for whole-genome or whole-exome sequencing and often struggle with the sparser data generated from targeted NGS panels used in routine genetic testing. Despite these challenges, several algorithms have been specifically adapted or developed to detect CNVs in targeted sequencing. Notable among these are DECON, GATK gCNV, and CNVKit. Each of these algorithms employs distinct strategies to analyze read depth, normalize data, and identify CNVs, contributing to their effectiveness in various research and clinical applications.

Detecting CNVs in targeted sequencing remains a difficult task due to several intrinsic challenges. The first major challenge is the inherent variability in read depth, which can be influenced by factors such as target capture efficiency, sequencing depth, and GC content. Variations in read depth can lead to both false positives and false negatives in CNV detection, making it crucial to apply robust normalization techniques to correct for these biases.

Another challenge is the short read lengths characteristic of NGS data, which can complicate the accurate alignment of reads to the reference genome, particularly in repetitive regions or regions with complex structural variations. Misalignment can lead to erroneous CNV calls, necessitating the use of sophisticated alignment algorithms and quality control measures to ensure accurate mapping.

Additionally, the targeted nature of sequencing panels means that only specific regions of the genome are sequenced, resulting in sparser data compared to whole-genome or whole-exome sequencing. This sparsity can make it difficult to accurately detect CNVs, especially those that span large genomic regions or occur in low-complexity regions. The reliance on targeted panels also means that any biases in probe design or capture efficiency can disproportionately affect the accuracy of CNV detection in certain regions.

% \section{Targeted CNV Learner}
% In this project, we present Targeted-CNV-Learner, a machine learning software that integrates calls from multiple CNV detection algorithms and learns to accurately
% identify true CNVs using caller-specific and genomic features from a set of in
% silico CNVs inserted in the samples. The primary objective of this project is to
% develop a model that enhances the precision and selectivity of various stan-
% dalone algorithms, offering an improved approach for CNV detection in clinical
% diagnostics using targeted sequencing.

\chapter{State of the art}

The detection of CNVs in targeted sequencing has seen substantial advancements due to improvements in sequencing technologies and bioinformatics tools. 

Algorithms for CNV detection in targeted sequencing typically leverage read depth information, which reflects the number of sequencing reads mapping to specific genomic regions. Variations in read depth can indicate the presence of CNVs, but accurately detecting these variations requires overcoming technical biases, such as GC-content bias, sequencing depth variability, and capture efficiency inconsistencies.
\begin{wrapfigure}{r}{10cm}
\caption{Figure illustrating how deletions and duplications are respectively decreasing and increasing the read depth in the affected genomic location.}\label{wrap-fig:1}
\includegraphics[width=10cm]{imatges/del_dup.png}
\end{wrapfigure} 
A common strategy used by different CNV callers is to apply various statistical distributions to model the aggregate read depth of the exons and use read-depth fluctuations between adjacent targeted regions to identify duplication or deletion events (Figure~\ref{wrap-fig:1})

% \begin{figure}[htb]
% \centering
% \includegraphics[width=12 cm]{imatges/del_dup.png}
% \caption{\label{fig:del_dup} }
% \end{figure}
Three prominent algorithms used for CNV detection in targeted sequencing are DECON, GATK gCNV, and CNVKit. These tools are designed to handle the nuances of targeted sequencing data, employing advanced statistical models and normalization techniques to distinguish true CNVs from background noise. Each algorithm has its unique approach to read depth analysis, normalization, and segmentation, contributing to their effectiveness in both research and clinical applications.

\section{GATK gCNV}

\hl{REVISA: aqui tens una ref}: \href{https://github.com/broadinstitute/gatk}{The Genome Analysis Toolkit (GATK)} is a comprehensive suite of tools designed to facilitate the discovery of genetic variants from high-throughput sequencing data. Developed by the Broad Institute, GATK is widely recognized for its robustness, accuracy, and efficiency in processing and analyzing genomic data. GATK gCNV (germline Copy Number Variants) is a specialized component within the GATK toolkit designed to detect CNVs in germline genomes. GATK-gCNV pipeline (Figure~\ref{fig:gatk-gcnv}) begins by collecting coverage information from genome-aligned reads over a set of predefined genomic intervals (a). Next, the original interval list is filtered to remove coverage outliers, unmappable genomic sequence, and regions of segmental duplications (b). Then, samples are clustered into batches based on read-depth profile similarity using PCA and each batch is processed separately (c).  Chromosomal ploidies are inferred using total read-depth of each chromosome (d). Finally, The GATK-gCNV model learns read-depth bias and noise
and iteratively updates copy number state posterior probabilities until a selfconsistent state is obtained; after convergence, constant copy number segments are found using the Viterbi algorithm along with segmentation quality scores.
    \begin{figure}[htb]
\includegraphics[width=13 cm]{imatges/gatk-gcnv.jpg}
\caption{\label{fig:gatk-gcnv} GATK-gCNV pipeline steps.}
\end{figure}

\section{DECoN}
\href{https://github.com/RahmanTeam/DECoN}{Detection of Exon Copy Number Variants (DECoN)} is a specialized algorithm designed to detect CNVs in exon regions using targeted sequencing data. To distinguish true CNVs from random fluctuations in read counts, DECoN employs a Bayesian statistical framework. This approach models the expected distribution of read counts and compares it to the observed data, estimating the likelihood that a given deviation is due to a CNV rather than noise. The Bayesian framework provides a rigorous method for assessing the confidence in each detected CNV. After completing the statistical analysis, DECoN identifies exons with significant deviations in copy number, flags them as potential CNVs, and associates a Bayesian factor with each, which helps differentiate true positive calls from noise.

    

\section{GRAPES}
\href{https://github.com/bdolmo/GRAPES}{Germline Rearrangement Analysis from Panel Enrichment Sequencing (GRAPES)} is a sophisticated computational algorithm designed to detect  CNVs and structural variations in genomic data using paired-end sequencing. Developed by B. del Olmo, the co-supervisor of this thesis, GRAPES leverages both read depth and breakpoint information to accurately identify genomic rearrangements.(Figure~\ref{fig:grapes})
\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.75]{imatges/grapes.png}
    \caption{\label{fig:grapes} GRAPES workflow.}
\end{figure}
        
        
        GRAPES extracts read signatures indicative of structural variations from both on-target and off-target reads. By analyzing the read depth across the genome, the algorithm detects regions with abnormal copy numbers, such as deletions or duplications. Additionally, GRAPES identifies breakpoints by extracting breakpoint-informative reads, including discordant read-pairs, soft-clipped reads, and split-reads.
        
        The algorithm normalizes read depth by GC-content and DNA-capturing specificity. Highly correlated samples are clustered together to create baseline illustrating how deleerences, which are stored in a database. Finally, a 4-state Hidden Markov Model, based on a Gaussian model with positional emission probabilities, is used to call preliminary CNVs. This process incorporates threshold and quality filters such as log2 ratio, z-scores, and phred score to ensure accurate variant detection.

%\textcolor{blue}{OBJECTIVES MOVED TO INTRODUCTION (first part) and PLANNING (remainder)}

\chapter{Planning}
To achieve \hl{the objectives, }\st{ this, we will undertake} the following steps \hl{have been undertaken}:

\begin{itemize}
    \item \textbf{Identify samples analyzed with the panel SUDD147}: We \st{will} identify the 400 most recent samples analyzed with the SUDD147 panel from the UDMMP database and obtain their aligned files (BAM files).
    \item \textbf{Identify samples with bad quality}: Samples with poor quality will be removed to prevent bias in our model, as inadequate coverage in these samples hinders accurate CNV detection.
    \item \textbf{Insert In Silico CNVs}: Given the rarity of CNVs (only 74 detected in over 2000 samples since 2017), we will insert in silico CNVs into the samples to create a sufficiently large dataset for training the model.
    \item \textbf{Run CNV detection algorithm\hl{s}}: We have developed a pipeline to run multiple CNV detection algorithms, automatically analyze the samples, and parse the resulting CNV calls.
    \item \textbf{Determine CNVs overlap between algorithms calls}: To avoid double counting CNV events, we will merge concordant CNV predictions from different callers that overlap in the same genomic region, treating them as single events for downstream analyses.
    \item \textbf{Label CNVs Calls}:  After merging overlapping calls, we will automatically label each CNV call as either a true CNV (in silico or previously detected) or an artifact. This labeling is crucial for training the machine learning model.
    \item \textbf{Model Construction}: With labeled CNV data, we will extract various genomic characteristics to aid the model in making accurate decisions.
    \item \textbf{Model Evaluation}: We will analyze how different variables affect the model, examining correlations and other aspects to understand its performance comprehensively.
\end{itemize}


\st{All these steps will be integrated into a pipeline, enabling the easy creation of new models for each panel. This approach ensures that the models are tailored to the specific characteristics of each panel, thereby improving the accuracy and reliability of CNV detection.

This structured pipeline will facilitate the continuous improvement and adaptation of CNV detection models for different genetic panels, enhancing the overall genetic analysis process.}


\chapter{Methodology}

\hl{A methodology has been defined to integrate all the steps required to achieve the objectives: predict CNV with multiple algorithms and by using insilico data. The pipeline is shown in Figure XXX. The availability of a pipeline  enables the easy creation of new models for any panel.  }

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.9\linewidth]{imatges/Overview.v6.pdf}
    \caption{Methodology overview}
    \label{fig:enter-label}
\end{figure}

\textcolor{blue}{ATENCIO. ES MOLT IMPORTANT QUE TOTES LES SECCCIONS D'AQUEST CAPÍTOL CORRESPONGUIN A UN PAS EN LA METODOLOGIA. Addicionalment, l'última secció s'anomena "Experimental set up". Ajusto segons el que he entès.  }

\section{Dataset}

\hl{[Moved]}Since UDMMP began sequencing, approximately 30,000 variants have been identified and stored in a MongoDB database.
\hl{The full process carried out is shown in Figure}  \ref{fig:variant_calling_workflow}. Due to high memory consumption, UDMMP has a policy of deleting intermediate analysis files, including BAM files, one year after analysis. To proceed with this project, we decided to retrieve the BAM ready for variant calling (Figure \ref{fig:variant_calling_workflow}) files from samples analyzed within the last year. This approach ensures an adequate sample size (approximately 400 samples) without the need to reprocess the raw FASTQ files, which would require significant computational resources to align and generate the BAM files.


%\begin{wrapfigure}{r}{5.8cm}
\begin{figure}  % M'ha clafiricat el text veure la figure sense wrap
\caption{Simplified workflow used for variant calling bioinformatic analysis with all the intermediate files created shown in red.}\label{fig:variant_calling_workflow}
\includegraphics[width=5.8cm]{imatges/variant_calling_workflow.png}
\end{figure} 

\section{DATA ACQUISITION}

To achieve reliable results with the Targeted CNV Learner, it is recommended to have at least 200 samples, \hl{due to the requirements of the CNV detection algorithms. For example, the GATK gCNV algorithm requires at least 100 samples for an initial step (baseline). Up to 400 samples have been selected.} \st{It is important to note that Targeted CNV Learner will reserve 100 of these samples for establishing the baseline required by the GATK gCNV algorithm. These baseline samples will be used exclusively to create the reference for CNV detection and will not be used for the insertion of in silico CNVs or subsequent model processing. }

%Since UDMMP began sequencing, approximately 30,000 variants have been identified and stored in a MongoDB database. Due to high memory consumption, UDMMP has a policy of deleting intermediate analysis files, including BAM files, one year after analysis. To proceed with this project, we decided to retrieve the BAM ready for variant calling (Figure \ref{fig:variant_calling_workflow}) files from samples analyzed within the last year. This approach ensures an adequate sample size (approximately 400 samples) without the need to reprocess the raw FASTQ files, which would require significant computational resources to align and generate the BAM files.

From the MongoDB database, we retrieved all samples for which BAM files are maintained, allowing us to download the aligned BAM files necessary for analysis.

Additionally, we obtained all the \st{copy number variations (}CNVs\st{)} detected in these samples that have been confirmed using an orthogonal technique \hl{(See Table XXX)}, specifically \st{Multiplex Ligation-dependent Probe Amplification (}MLPA \hl{(see Section} \ref{sec:back-detectionCNV}). This step is crucial because, despite introducing in silico CNVs, it is essential to consider all previously detected CNVs in the samples. Ignoring these CNVs would result in incorrectly labeled data for the model. These confirmed CNVs will be used to validate the model's results, as they represent real variants and will help determine the model's accuracy without relying solely on in silico CNVs.

\begin{table}[tb]
    \centering
%    \begin{tabular}{c|c}
%         &  \\
%         & 
%    \end{tabular}
    \caption{Posa aquí la taula de la slide titulada "Collection of previously identified CNVs}
    \label{tab:my_label}
\end{table}

\section{Quality assessment and outlier detection} \label{read_depth_section}

\hl{The aim of this step is to filter out samples that do not fulfill a given quality. }

Read depth profiles are a crucial tool for assessing the quality of sequencing data. They provide a snapshot of the coverage across different regions of the genome, offering insights into the uniformity and adequacy of the sequencing process. In the context of targeted sequencing panels, read depth profiles are particularly useful for identifying samples with poor quality as:

\begin{itemize}
    \item \textbf{Uniform coverage}: High-quality sequencing data should exhibit uniform coverage across the targeted regions. Significant deviations in read depth can indicate issues such as poor sample quality, sequencing errors, or library preparation problems. Uniform read depths ensures that each region of interest is adequately covered, which is essential for reliable CNV detection.
    \item \textbf{Detection of anomalies}: Samples with poor quality often show anomalies in their read depth profiles, such as regions with excessively high or low coverage. These anomalies can lead to false-positive of false-negative variant calls, thereby compromising the accuracy of downstream analyses.
\end{itemize}
To systematically assess the quality of samples using read depth profiles, the following methodology is employed

\subsection{Calculation of Mean Read Depth} \label{mean_read_depth}
For each sample, the mean read depth is calculated for each exon in the targeted panel using the software 
\href{https://github.com/brentp/mosdepth}{Mosdepth} (https://pubmed.ncbi.nlm.nih.gov/29096012/). This involves summing the read depths for each position within an exon and then averaging these values (Figure \ref{fig:mosdepth}). The resulting mean read depths for all exons constitute the read depth profile of the sample.

To ensure comparability between samples, the read depth profiles are normalized and standardized by the mean read depth of the sample. This step adjusts for variations in overall sequencing depth and other systematic biases, enabling a fair comparison across different samples.

\begin{figure}[htb]
\centering
\includegraphics[width=14 cm]{imatges/mosdepth.png}
\caption{\label{fig:mosdepth} Illustration of Mosdepth's method for calculating read depth at each position. For every read start position, the value in the corresponding position of the array is incremented. Conversely, for every read stop position, the value in that position is decremented. This process accurately reflects the read depth distribution across the targeted region.}
\end{figure}
\subsection{Principal Component Analysis}
PCA is a statistical technique used to reduce the dimensionality of large datasets while preserving most of the variance. By applying PCA to read depth profiles, we can transform the high-dimensional data into smaller set of principal components. These components capture the most significant patterns of variation in the data.

The first two principal components obtained from PCA can be visualized in scatter plots, where each point represents a sample. Samples with similar read depth profiles cluster together, while outliers, indicative of poor-quality samples, appear separated from the main cluster. Based on the PCA results, we use the z-score method to identify the outliers. The z-score for the first and second principal components (PC1 and PC2) is calculated to standardize these values, enabling comparison on a common scale. The z-score for PC1 is computed by subtracting the mean of PC1 values from each PC1 value and then dividing the result by the standard deviation of the PC1 values. Similarly, the z-score for PC2 is obtained by subtracting the mean of PC2 values from each PC2 value and then dividing the result by the standard deviation of the PC2 values. Mathematically, these are expressed as:

\[
\text{PC1\_zscore} = \frac{\text{PC1} - \overline{\text{PC1}}}{\sigma_{\text{PC1}}}
\]
\[
\text{PC2\_zscore} = \frac{\text{PC2} - \overline{\text{PC2}}}{\sigma_{\text{PC2}}}
\]

where $\text{PC1}$ and $\text{PC2}$ represent the principal component values, $\overline{\text{PC1}}$ and $\overline{\text{PC2}}$ denote the mean values, and $\sigma_{\text{PC1}}$ and $\sigma_{\text{PC2}}$ signify the standard deviations of the principal component values.

Outliers are identified based on a predefined threshold, denoted as the z\_score\_threshold. A sample is considered an outlier if the absolute value of its z-score for either PC1 or PC2 exceeds this threshold. Specifically, a data point is flagged as an outlier if:

\[
\left| \text{PC1\_zscore} \right| > \text{z\_score\_threshold} \quad \text{or} \quad \left| \text{PC2\_zscore} \right| > \text{z\_score\_threshold}
\] 



The z\_score\_threshold can be determined by the user using the z\_score\_threshold flag. Samples flagged as outliers are considered to fall outside the acceptable range of variation and are flagged as poor quality. These samples are then excluded from further analysis to prevent bias and ensure the integrity of the dataset.

\section{INSERTION OF IN SILICO CNVs}

In order to develop a robust machine learning model capable of distinguishing between true positive CNV calls and false negative calls from different algorithms, it is essential to have a sufficiently large sample size. This ensures the model can learn from a diverse and representative set of examples, which is critical for accurate classification and generalization to new data.

However, obtaining a sufficiently large sample size for training the model is challenging due to the low recurrence of CNVs in targeted sequencing, where only a subset of genes is analyzed. CNVs are relatively rare events, especially in focused gene panels, where the likelihood of encountering multiple CNVs in a single sample is low. This rarity limits the availability of naturally occurring CNVs in our dataset, thereby constraining the number of positive examples available for model training.

To address this limitation, we employ in silico insertion of CNVs into the BAM files. In silico CNVs are artificially generated variants that are computationally inserted into existing BAM files. This technique allows us to augment our dataset with additional CNV examples without the need for new sequencing efforts or the reprocessing of raw data. By creating these synthetic CNVs, we can significantly increase the number of positive samples in our dataset.

The inclusion of in silico CNVs is crucial for several reasons:

\begin{itemize}
    \item \textbf{Enhanced training data}: By artificially increasing the number of CNV examples, we provide the machine learning model with more instances to learn from, improving its ability to recognize true CNVs and differentiate them from false positives
    \item \textbf{Balanced dataset}: Machine learning models perform better when trained on balanced datasets. The low natural occurrence of CNVs results in an imbalanced dataset with a high proportion of negative examples. In silico CNVs help balance the dataset, leading to more effective training.
    \item \textbf{Comprehensive learning}: In silico CNVs can be designed to cover a wide range of scenarios, including different types of CNVs, varying sized, and different genomic contexts. This diversity ensures that the model learns to detect CNVs under various conditions, enhancing its robustness and accuracy.
\end{itemize}

\hl{It is wothy to observe that both, in-silico CNVs and real CNVs that have been previously confirmed in the samples are required} . \st{Despite the introduction of in silico CNVs, it is important to validate the model using real CNVs that have been previously confirmed in the samples. This step ensures that the model's performance is not solely dependent on synthetic data but is also accurate in real-world scenarios.}  The combination of real and in silico CNVs provides a comprehensive dataset for training and validation, ultimately leading to a more reliable and effective machine learning model for CNV detection.

\hl{In silico CNVs are inserted using the Spike technique. ???? Com lliga amb el que segueix.}

\subsection{Spike in BAM}
The insertion of in silico CNVs is a common technique in CNV analysis studies (references). This approach is widely adopted to augment datasets with synthetic CNVs, enabling the development and validation of CNV detection algorithms. Various algorithms have been developed to facilitate the insertion of in silico CNVs into NGS data (references). For this project, we have chosen to use \href{https://github.com/bdolmo/SpikeInBAM}{Spike in BAM}. Spike in BAM allows the insertion of CNVs directly into BAM files with the use of a simple configuration file (Figure~\ref{fig:config_file}). This configuration file must include the BAM file path, the start and end positions of the CNV, the type of CNV (duplication or deletion), and the exons encompassed by the CNV.

\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.45]{imatges/config_file.png}
    \caption{\label{fig:config_file} Example of the configuration file needed to insert CNVs using Spike in BAM. The configuration file should include the BAM file path, the start and end of the CNV, the type of CNV (duplication or deletion) and the exons that englobes the CNV.}
\end{figure}

One of the key advantages of Spike in BAM is its ability to utilize multiple cores, significantly improving execution time. Additionally, Spike in BAM modifies the variant allele frequencies of any SNPs that overlap with the simulated CNV, providing a more realistic representation of CNV insertion. This feature ensures that the synthetic CNVs closely resemble naturally occurring variants, enhancing the robustness of the dataset for training and validating CNV detection models.

To automate the insertion of CNVs into BAM files, the Targeted CNV Learner generates a configuration file from a \textcolor{blue}{BED} file, which specifies the genomic regions of interest. This auto-generated configuration file enables the subsequent execution of Spike in BAM to create in silico CNVs within the BAM files, while maintaining a detailed record of all inserted CNVs.

In the analysis case with the panel of SUDD147, 4 CNVs were inserted in each sample: 
\begin{itemize}
    \item 1 single exon duplication
    \item 1 multiple exon duplication
    \item 1 single exon deletion
    \item 1 multiple exon deletion
\end{itemize}


\section{Run CNV detection algorithms}
The subsequent phase of the project involves the automated execution of three CNV detection algorithms across the samples to identify Copy Number Variants (CNVs). This process is crucial for comparing the performance of different algorithms and ensuring comprehensive CNV detection.

To achieve this, we have developed a pipeline module that automatically runs the following CNV detection algorithms:
\begin{enumerate}
    \item GRAPES
    \item GATK g-CNV
    \item DECON
\end{enumerate}

The Targeted-CNV-Learner pipeline integrates these algorithms into a seamless workflow, ensuring efficient and reproducible CNV detection. The key features of the pipeline include:
\begin{itemize}
    \item \textbf{Automated execution}: The pipeline automates the execution of GRAPES, GATK g-CNV, and DECON, minimizing manual intervention and reducing the potential for human error.
    \item  \textbf{Data management}: It efficiently manages the input data, ensuring that the corresponding samples are processed together.
    \item \textbf{Result parsing}: The pipeline automatically parses the CNV calls from each algorithm, facilitating the integration of the results for downstream analyses.
\end{itemize}
 \st{efficiently managing the input data, ensuring that the correct samples are processed together and}. Finally the pipeline automatically parses the CNV calls from each algorithm, facilitating the integration of the results. \hl{AIXO no esta explicat/no s'enten. PARLAR }

\subsection{GRAPES and DECON}
Both GRAPES and DECON are designed to operate on each sequencing run. This means they analyze all the samples that were prepared and sequenced together as a batch. By processing these \hl{algorithms} collectively, we can mitigate the technical biases introduced during the sample preparation and sequencing process. This batch-wise analysis ensures more consistent and reliable CNV detection across samples prepared under similar conditions.

\subsection{GATK g-CNV}
In contrast to GRAPES and DECON, GATK g-CNV employs a cohort-based approach. This method involves the following steps:
\begin{enumerate}

    \item \textbf{Cohort Mode}: GATK g-CNV uses a cohort of 100 samples to establish a baseline read depth profile. These samples are selected to represent the typical read depth distribution across the targeted regions.

    \item \textbf{Baseline Creation}: The read depth profile generated from the cohort serves as a reference. This profile captures the expected read depth variations under normal conditions, accounting for systematic biases and variability inherent to the sequencing process.

    \item \textbf{Comparison and Detection}: Each sample to be analyzed is then compared against this baseline read depth profile. By evaluating deviations from the baseline, GATK g-CNV can detect CNVs with greater precision. This approach enhances the accuracy of CNV detection by reducing false positives and ensuring that true CNVs are more reliably identified.
\end{enumerate}

\section{Detected CNV overlap analysis} \label{algorihtm_calls}
Once we have the calls from all the algorithms and the register of the inserted \textit{in silico} CNVs, it's expected that the detected CNVs \st{will} \hl{do} not have identical coordinates across different algorithms and not match exactly with the in silico CNV inserted. Therefore, we need a robust approach to determine when different CNVs, identified by different algorithms and/or match and in silico-cnv, should be considered equivalent based on their overlapping regions.

In this study, we employ a method in Targeted-CNV-Learner that deems two CNVs to be the same if there is a minimal percentage of overlap between them. Specifically, two CNVs are considered equivalent if they share at least user-given \% of their lengths.

For example, consider the following CNVs:

% Exemple de taula:
\begin{table}[htb]
\centering
\begin{tabular}{ | r | c | c | c | l | }
 \hline
   & Chromosome & Start & End & Algorithm\\
\hline
 CNV call 1  & 2 & 1233 & 2000 & DECoN\\
 CNV call 2  & 2 & 1200 & 1633 & GRAPES\\
 In silico CNV & 2 & 1320 & 2100 & Real CNV\\
 
  \hline
  \end{tabular}
\caption{CNVs for overlap demonstration. CNV call 1 and CNV call 2 are identified by different algorithms, and the \textit{in silico} CNV is an artificially inserted CNV for validation.}
\label{table:CNVs_demostration} 
\end{table}

These CNVs will be considered equivalent if there is sufficient overlap between them, as defined by a percentage threshold. This threshold can be specified by the Targeted-CNV-Learner user through a specific flag.

In our case study, we have decided to use a 20\% threshold. Since CNVs should be confirmed by an orthogonal technique, we are not stringent about the precise positioning of the CNVs; our primary focus is on the presence or absence of the CNV.

To illustrate the process of determining if the CNVs have sufficient overlap to be considered the same, consider the following example:

To determine if CNV call 1 and CNV call 2 (Table \ref{table:CNVs_demostration}) can be considered the same, we need to perform the following calculations:

\textbf{Overlap region calculation}:


\[
\text{Overlap} = \min(\text{end}_1, \text{end}_2) - \max(\text{start}_1, \text{start}_2) = 1633 - 1233 = 400
\]

\textbf{Total length of CNV1:}

\[
\text{Length}_{\text{CNV1}} = 2000 - 1233 = 767
\]

\textbf{Total length of CNV2:}

\[
\text{Length}_{\text{CNV2}} = 1633 - 1200 = 433
\]

\textbf{Percentage overlap for CNV1:}

\[
\text{Overlap}_{\text{CNV1}} = \left( \frac{400}{767} \right) \times 100 = 52.14\%
\]

\textbf{Percentage overlap for CNV2:}

\[
\text{Overlap}_{\text{CNV2}} = \left( \frac{400}{433} \right) \times 100 = 92.38\%
\]
Since both percentages exceed the 20\% threshold, CNV1 and CNV2 are considered the same CNV. The coordinates for the resulting CNV are determined by taking the furthest boundaries, resulting in:
\begin{table}[htb]
\centering
\begin{tabular}{ | r | c | c | c | l | }
 \hline
   & Chromosome & Start & End & Algorithm\\
\hline
 Overlapped CNV  & 2 & 1200 & 2000 & DECoN and GRAPES\\
  \hline
  \end{tabular}
\caption{Final CNV.}
\label{table:CNV_final} 
\end{table}

This approach allows us to consider CNVs that overlap in the same region as the same CNV, while excluding those that have significantly different lengths.

\section{Labelling CNVs}

After overlapping the CNV calls from various algorithms, the next step is to \hl{label} these overlaps based on their correspondence with in silico CNVs. This \hl{process} allows us to accurately label the CNVs as true positives or false negatives. We \st{will} use the approach outlined in the previous section (\ref{algorihtm_calls}) and refer to the example provided in Table \ref{table:CNV_final_silico}.
\begin{table}[htb]
\centering
\begin{tabular}{ | r | c | c | c | l | }
 \hline
   & Chromosome & Start & End & Algorithm\\
\hline
 Overlapped CNV  & 2 & 1200 & 2000 & DECoN and GRAPES\\
 In silico CNV & 2 & 1320 & 2100 & Real CNV\\
  \hline
  \end{tabular}
\caption{Comparision of final CNV against in silico CNV.}
\label{table:CNV_final_silico} 
\end{table}



\textbf{Overlap region calculation}:


\[
\text{Overlap} = \min(\text{end}_1, \text{end}_2) - \max(\text{start}_1, \text{start}_2) = 2000 - 1320 = 680
\]

\textbf{Total length of Final CNV:}

\[
\text{Length}_{\text{Overlapped CNV}} = 2000 - 1200 = 800
\]

\textbf{Total length of in silico CNV:}

\[
\text{Length}_{\text{in silico CNV}} = 2100 - 1320 = 780
\]

\textbf{Percentage overlap for Overlapped CNV:}

\[
\text{Overlap}_{\text{Overlapped CNV}} = \left( \frac{680}{800} \right) \times 100 = 85\%
\]

\textbf{Percentage overlap for in silico CNV:}

\[
\text{Overlap}_{\text{in silico CNV}} = \left( \frac{680}{780} \right) \times 100 = 87,18\%
\]

Since both percentages exceed the 20\% threshold, the in silico CNV is considered to be detected by the overlapped CNV.

This approach allows us to classify each overlapped algorithm call as a true positive (if an in silico CNV overlaps with the call) or a false positive (if an in silico CNV does not overlap with the call).

\begin{table}[htb]
\centering
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{ | r | c | c | c | c | c | c | l | }
 \hline
   & Chromosome & Start & End & Grapes & DECoN & GATK gCNV & Overlap in silico \\
\hline
 Overlapped CNV  & 2 & 1200 & 2000 & True & True & False & True\\

  \hline
  \end{tabular}
  \end{adjustbox}
\caption{Labels assigned to the Overlapped CNV containing if the CNV was detected by the different algorithm and if it overlaps a inserted in silico CNV.}
\label{table:CNV_labelled} 
\end{table}


\section{Data model construction}

The construction of a robust predictive model requires the extraction of \hl{additional} features from the labeled CNVs.\hl{The goal of this steps is to gather complementary data from the obtained CNVs from external repositories .}
 These features are essential for enhancing the model's ability to differentiate between true CNVs and artifacts. 
 
 \hl{Features selected can be grouped in two blocs: context variables and quality samples variables. These features are combined with the quality variables obtained after the labelling step, yielding to the final data model shown in Table } \ref{tab:dataModel}. For the sake of completeness, all variables are detailed below. 

\textcolor{blue}{Atencio: les descripcions de les variables les he combinat entre el que tenies aqui i la repeticio que posaves a la part de resultats. Als resultats les elimino.}

\begin{table}[]
    \centering
    \begin{tabular}{c|p{7cm}}
        \hline
         Type & Features \\
         \hline
         CNV quality & decon, gatk, grapes, decon\_qual, gatk\_qual, grapes\_qual\\
         \hline
         CNV genomic context  & chr, type, numb\_exons, gc\_content, mappability, cnv\_length, gene\\
         \hline
         Quality samples & sample\_correlation\\
         \hline
         Target & true\_positive\\
         \hline
    \end{tabular}
    \caption{Data model}
    \label{tab:dataModel}
\end{table}

\subsection{CNV quality variables}

 Each CNV detection algorithm provides a quality score for its calls, based on its internal calculations. These quality scores are informative about the reliability of the CNV calls and are included as features in the model.
 
\begin{itemize}
\item \textbf{DECoN Call (decon)}: Indicates if a DECoN call overlaps the CNV.
\item \textbf{GATK gCNV Call (gatk)}: Indicates if a GATK gCNV call overlaps the CNV.
\item \textbf{Grapes Call (grapes)}: Indicates if a Grapes call overlaps the CNV.
\item \textbf{DECoN Quality (decon\_qual)}: The quality score assigned by DECoN to the CNV call, available only if DECoN made a call overlapping the CNV.
\item \textbf{GATK gCNV Quality (gatk\_qual)}: The quality score assigned by GATK gCNV to the CNV call, available only if GATK made a call overlapping the CNV.
\item \textbf{Grapes Quality (grapes\_qual)}: The quality score assigned by Grapes to the CNV call, available only if Grapes made a call overlapping the CNV.
\end{itemize}

\hl{It is worthy to observe, that the start and end data of CNVs (see Table } \ref{table:CNV_labelled} \hl{are not considered, because ...... Moreover, chromosome is provided in the context variables (?). COMPLETA } 

\subsection{Context variables}

Context features are the following: 
    \begin{itemize}
     \item \textbf{Chromosome (chr)}: The chromosome on which the CNV is located. \hl{ATENCIO: aqueta esta posada com a context, i sembla que la tenies tambe abans a la taula 5.5, per tant, no se ben be si la provenca es els repositoris o el teu dataset original}
    \item \textbf{CNV type(type)}: The type of CNV (duplication or deletion) is provided to the model as an essential feature.

    \item \textbf{Exon number in gene (num\_exons)}: False-positive CNV calls tend to accumulate in the first exons of genes due to their properties (e.g., higher GC content) and technical factors related to sequencing (e.g., mapping artifacts, capture efficiency, read start position bias). Including the exon number in the gene as a feature helps the model account for these tendencies.
    \item \textbf{GC content (gc\_content)}: GC content is a well documented bias that significantly affects NGS data (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3378858/). Regions with high or low GC content can exhibit differential sequencing efficiency and read depth, leading to false-positive CNV calls. By calculating the GC content for each CNV, we can help the model account for these biases, potentially increasing the reliability of CNV detection.
    \item \textbf{Mappability (mappability)}: Low mappability regions can cause ambiguous read alignment and reduced accuracy in CNV detection. By incorporating mappability scores (https://pubmed.ncbi.nlm.nih.gov/22276185/), the model can better identify areas of the genome where sequencing data may be less reliable, thus improving its ability to distinguish between genuine CNVs and artifacts.
    \item \textbf{CNV length (cnv\_length}: CNV detection algorithms often struggle with short CNVs (those spanning a single exon or a small number of exons). Including the length of the CNV as a feature can help the model improve its accuracy.
    \item \textbf{Gene (gene)}:  Certain genes are more prone to CNV calls due to their inherent properties. Providing the gene information as a parameter can help the model improve its predictive metrics by accounting for gene-specific biases.

    \end{itemize}

\subsection{Quality samples variables}

\hl{There is a single quality sample variable: Sample correlation over cohort samples (sample\_correlation)}. In our analysis, it is crucial to assess the quality of the sample and the sequencing process to reliably detect copy number variations (CNVs). One way to achieve this is by calculating the correlation of the normalized read depth profiles of the analysis sample with those of a cohort of samples. This correlation helps identify the degree of similarity between the analysis sample and the cohort, providing insights into the reliability of detected CNVs. The steps followed to obtain this calculation are the following ones: 


Should I add the notation of this calculation in the appendix? Or I left it here? \hl{Com ara ho hem separat en subseccions, es pot deixar aquí. }
The following steps outline the process of calculating the sample correlation:

\begin{itemize}
       \item \textbf{Normalization of Read Depth}: For each sample \(i\) in both the cohort and the analysis sample, the read depth for each exon \(j\) is normalized. This is done by dividing the read depth of the exon \(\text{RD}_{ij}\) by the mean read depth of the corresponding sample \(\overline{\text{RD}}_i\):
       \[
       \text{NRD}_{ij} = \frac{\text{RD}_{ij}}{\overline{\text{RD}}_i}
       \]
       where \(\text{NRD}_{ij}\) is the normalized read depth for exon \(j\) in sample \(i\).


    \item \textbf{Computation of Correlations}:The Spearman correlation coefficient \(\rho\) is calculated between the normalized exon coverage profile of the analysis sample \(\mathbf{X}\) and each sample in the cohort \(\mathbf{Y}_k\). The Spearman correlation is chosen for its robustness in handling non-linear relationships and varying distributions:
       \[
       \rho(\mathbf{X}, \mathbf{Y}_k) = \frac{\text{cov}(\text{rank}(\mathbf{X}), \text{rank}(\mathbf{Y}_k))}{\sigma_{\text{rank}(\mathbf{X})} \sigma_{\text{rank}(\mathbf{Y}_k)}}
       \]
       where \(\text{rank}(\mathbf{X})\) and \(\text{rank}(\mathbf{Y}_k)\) are the ranks of the normalized read depth values of the analysis sample and cohort sample \(k\) respectively, \(\text{cov}\) is the covariance, and \(\sigma\) is the standard deviation.

    \item \textbf{Mean Correlation Value}: The mean of the correlation values is computed:
       \[
       \overline{\rho} = \frac{1}{N} \sum_{k=1}^{N} \rho(\mathbf{X}, \mathbf{Y}_k)
       \]
       where \(N\) is the number of cohort samples. This mean correlation \(\overline{\rho}\) provides a single metric that reflects the overall similarity between the analysis sample and the cohort. A higher mean correlation indicates a higher degree of similarity and thus greater reliability in CNV detection.
   \end{itemize}


\subsection{Target variable}
The target variable for prediction is:\textbf{True Positive CNV Call (true\_positive)}: Indicates whether the CNV overlaps an in-silico CNV, thereby determining if it is a True Positive call (True) or not (False).


\section{ML selection }

The selection of an optimal model with the best parameters is crucial to ensure that we are leveraging the most effective approach for achieving superior results. In our dataset, various variables may contain null values, particularly when the quality of a CNV detection algorithm is not applicable if the CNV was not detected by that specific algorithm. Consequently, it is imperative to select a model capable of effectively handling such missing data.

Two prominent machine learning approaches that accommodate null values are Random Forest and XGBoost. Both methods are based on decision trees, which inherently provide several advantages for handling missing values. 

Random forest constructs multiple decision trees during training and in outputs the mode of the class (classification) or the mean prediction (regression) of the individual trees. Random forest can handle null values gracefully as it builds trees using only the available data and can make decisions based on subsets of features without the need of imputation.

Extreme Gradient Boosting (XGBoost),builds a series of decision trees, where each new tree attempts to correct errors made by the previous trees. XGBoost during the training process, it learns which direction to take in the presence of missing values and uses them to split nodes appropriately, thus maintaining model performance even with incomplete data.

\section{Feature selection}

\begin{wrapfigure}{r}{0.55\textwidth}    \centering
    \includegraphics[width=0.55\textwidth]{imatges/feature_sel_process.png}
    \caption{\label{fig:feature_sel}Feature selection process illustrating the impact of removing the least contributing feature on the model.}
\end{wrapfigure} 
Once we have established that XGBoost is the best model for our dataset, we will employ feature selection to enhance the performance and interpretability of our model. It is crucial to identify and retain only the most relevant features to improve model efficiency and accuracy (https://www.sciencedirect.com/science/article/pii/S0957417421012513).


Tree-based models, such as XGBoost, inherently provide a measure of feature importance. This measure reflects the contribution of each feature to the reduction of impurity in the model's decision trees. By leveraging these feature importance scores, we can rank all features and eliminate the less significant ones, thereby reducing dimensionality and potentially improving model performance. We will use feature selection based on feature importance to reduce the number of features included in the model without compromising its feasibility, following the process represented in Figure \ref{fig:feature_sel}.

By implementing this approach, we aim to achieve a more streamlined and interpretable model without compromising its predictive power. This process will help us strike a balance between model simplicity and performance, ensuring that the final model remains both effective and manageable.

\section{Experimental set-up}

\hl{The panel used in this work is the 147..... COMPLETA.  } 

\textcolor{blue}{Mogut. Abans ho tenies quan explicaves les variables} The training data for the model is available \href{https://docs.google.com/spreadsheets/d/1UfV6gHaIB-vmFPgmuTZWS0HOmq40BCJS/edit?gid=793808968#gid=793808968}{here}, with an example provided in Appendix Table \ref{tab:Model_input}. (ficar link a carpeta amb explicació de cada variable al github I en obert!)



To ensure the robustness and accuracy of the predictive models, we \st{will} conduct a comprehensive evaluation process. This section outlines the evaluation strategy, including the methods for \hl{selecting the predictive model}, analyzing feature impact, and \hl{validating the final model}.

\hl{Revisa al final si has fet un train/test split inicial.}
\subsection{Model selection assessment}

%We will evaluate several models, specifically choosing those capable of handling missing values. This is crucial because some characteristics related to the algorithm calls (e.g., algorithm call quality) may not be calculable if the call was not performed by the algorithm in question.   
%For each model, we will perform the following steps:

For each model, we will use a rigorous cross-validation strategy to ensure reliable performance metrics \hl{concreta si pots la k (5-cv, ...)}. This approach involves randomly splitting the dataset into training and testing subsets ten times. For each split, the model will be trained on the training set and evaluated on the testing set. To mitigate the effects of data variability and provide a robust estimate of model performance, we will report the mean results across these ten runs.

The performance of each model will be assessed using several metrics, illustrated in Figure \ref{fig:evaluation_metrics}:
\begin{itemize}
\item \textbf{Accuracy}: The proportion of correctly classified instances out of the total instances.
\item \textbf{Selectivity (Specificity)}: The proportion of true negatives correctly identified by the model.
\item \textbf{Sensitivity (Recall)}: The proportion of true positives correctly identified by the model.
\item \textbf{F1 Score}: The harmonic mean of precision and recall, providing a single metric that balances both aspects of performance.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.35]{imatges/model_metrics.png}
    \caption{\label{fig:evaluation_metrics} Model metrics used to evaluate the model.}
\end{figure}
The mean values of these metrics across the ten runs will be reported to provide an overall assessment of each model's performance.

\subsection{Feature Impact Analysis}

To gain insights into how different variables affect the model's predictions, we will conduct a comprehensive feature importance analysis. This analysis will particularly focus on models such as Random Forests, which provide feature importance scores that help us understand which variables most significantly influence the model's predictions. By ranking these scores, we can identify and prioritize the most impactful features.

%Additionally, we will perform a correlation analysis to explore the relationships between model variables and the output variable. First, we will evaluate the correlation coefficients to quantify the strength and direction of relationships between each feature and the model's output. We will also use correlation heatmaps to visually represent these relationships, providing an overview of how features are interrelated and their impact on the model's predictions.

In addition to evaluating feature importance, we will explore strategies to simplify the model by removing less significant variables. The goal is to reduce model complexity while maintaining or even improving the performance metrics. This will involve a careful selection process where variables with lower importance scores are systematically removed, and the model is re-evaluated to ensure that the removal of these features does not lead to a decrease in key performance metrics such as accuracy, sensitivity, and F1 Score.

%By implementing this approach, we aim to achieve a more streamlined and interpretable model without compromising its predictive power. This process will help us strike a balance between model simplicity and performance, ensuring that the final model remains both effective and manageable.

%\subsection{Model Interpretation and Scoring}
\subsection{Model validation}

\hl{Concreta si pots si ho has fet amb el 20\%de l'esplit}
For models like Random Forests, we will analyze the scoring mechanism by evaluating the percentage of trees in the forest that produce a specific output. This scoring provides insight into the model's consensus and helps assess the robustness of its predictions.

We will also interpret these scores to understand their contribution to the overall results. For instance, a high percentage of trees consistently predicting the same outcome indicates strong model confidence, while variability in scores might reveal data complexity or uncertainty.

By employing these evaluation strategies, we aim to thoroughly assess the performance, interpretability, and reliability of our predictive models, ensuring that the results are both accurate and actionable.




\chapter{RESULTS AND DISCUSSION}

This \hl{chapter} presents the results of our \hl{methodology. First we provide the results regarding the outlier analysis. Next, the  results on the existing CNVs detecting  models are detailed. Afterwards, an exploration data analysis of all the varibles gathered in the methodology is provided. Finally, the results of the model selection, feature selection and final model are provided. }

%model and compares them to the performance of stand-alone CNV detection algorithms, which represent the current state-of-the-art methods for CNV identification.

\hl{Si finalment introdueixes l'experimentació amb real CNVs, ho poses. Sino no passa res, tens prou feina per reportar}

\section{Identification of Samples with Bad Quality}


Samples of poor quality, whether due to the quality of the extracted tissue or issues arising from the NGS protocol, exhibit anomalies in their read depth profiles that can hinder the detection of CNVs. Such anomalies bias the results, making it crucial to identify and remove these samples from the analysis.

To address this, we employed PCA to reduce the dimensionality of the read depth data for each exon, as detailed in Section \ref{read_depth_section}. PCA allows us to capture the most significant patterns of variation in the data, thereby facilitating the identification of outliers.
\begin{wrapfigure}{r}{0.65\textwidth}
    \centering
    \includegraphics[width=0.658\textwidth]{imatges/outliers_pca.png}
    \caption{\label{fig:outliers} PCA plot illustrating the clustering of high-quality samples and the dispersion of poor-quality samples.}
\end{wrapfigure}

Figure \ref{fig:outliers} shows the outlier detection performed on SUDD147 samples using a z\_score\_threshold of 2. In this PCA plot, each point represents a sample, with colors indicating whether a sample is classified as an outlier or not. The majority of samples cluster tightly together, indicating uniform and high-quality sequencing data. However, a number of samples are dispersed across the plot, representing the poor-quality samples.

By cross-referencing these outlier samples with the quality metrics previously obtained by the group, we confirmed that the identified poor-quality samples were correctly detected. This validation step is crucial, as it ensures that the removal of these outliers is justified, thereby preserving the integrity and accuracy of the CNV detection process.

The clustering of high-quality samples and the dispersion of outliers highlight the effectiveness of the PCA and z-score method in distinguishing between samples of varying quality. Removing these outliers from further analysis minimizes bias and enhances the reliability of the results.



\section{Evaluation of Stand-Alone CNV Detection Methods} \label{standalone_algorithms}


\begin{wrapfigure}{r}{0.6\textwidth} % 'r' for right, '0.5\textwidth' for the width of the figure environment
    \centering
    \includegraphics[width=0.6\textwidth]{imatges/algorithms_metrics.png} % Adjust the width as necessary
    \caption{\label{fig:stand_alone_detection_algorithm} Illustrates the comprehensive workflow of genomic DNA targeted sequencing.}
\end{wrapfigure}
This section presents an in-depth evaluation of the three CNV detection algorithms utilized in this project: GATK, DECoN, and Grapes. Our analysis emphasizes the performance of these algorithms in detecting CNVs across varying exon counts, with particular focus on their effectiveness and accuracy in identifying CNVs with smaller exon sizes.

A total of 1161 in silico CNVs were introduced for evaluation. Figure \ref{fig:stand_alone_detection_algorithm} summarizes the performance metrics for the stand-alone CNV detection algorithms:

\begin{itemize}
\item \textbf{DECoN}: DECoN detected the highest number of CNVs, identifying 1048 out of 1161. However, it also generated a significant number of false positives, totaling 1450. Consequently, DECoN achieved a precision of 0.4195 and a false discovery rate (FDR) of 0.5804.
\end{itemize}


\begin{itemize}
    \item \textbf{GRAPES}: GRAPES correctly identified 660 CNVs and produced 780 false positives, resulting in a precision of 0.4583 and an FDR of 0.5417.
    
    \item \textbf{GATK gCNV}: GATK gCNV identified 770 CNVs with 471 false positives, achieving the highest precision of 0.6205 and the lowest FDR of 0.3795 among the evaluated algorithms.
\end{itemize}
Collectively, these algorithms detected a total of 1083 CNVs, leaving 78 CNVs undetected. These undetected CNVs highlight the inherent challenges in current CNV detection methodologies.

A common challenge among all CNV detection algorithms is their reduced effectiveness in detecting CNVs with a small number of exons (https://www.nature.com/articles/s41431-020-0675-z). Figure \ref{fig:evaluation_numb_exons} illustrates the precision and recall of each algorithm across varying exon counts, highlighting their performance in detecting CNVs with smaller exon sizes. All three algorithms show diminished precision and recall at lower exon counts, indicating that CNVs with fewer exons are more challenging to detect accurately. This leads to either missed detections (lower recall) or incorrect predictions (lower precision).

DECoN stands out with the highest recall, indicating its strong capability to detect a wide range of CNVs. However, this high recall comes at the expense of precision, resulting in a higher rate of false positives. This trade-off between recall and precision is critical, especially in applications where the cost of false positives must be carefully balanced against the necessity to detect as many true CNVs as possible. GATK and Grapes maintain high precision but with a slight compromise in recall, particularly at extreme exon sizes. DECoN, conversely, offers higher recall but at a notable drop in precision.

By combining the outputs of these three algorithms into a machine learning model, incorporating genomic characteristics of the CNV call region, we anticipate improving the overall ability to accurately detect CNVs. This approach aims to enhance the FDR without compromising the detection capability, ultimately providing a more robust and reliable CNV detection framework.


\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.27]{imatges/precision_vs_recall2.png}
    \caption{\label{fig:evaluation_numb_exons} Precision and recall of the different algorithms plotted against the minimum number of exons a CNV has. For example, data points for \textit{Minimum Number of Exons} = 1 include all CNV calls that have 1 or more exons. The figures are truncated at \textit{Minimum Number of Exons} = 8 as, out of the 2992 total CNV calls made by the algorithms, 2888 calls involve CNVs with 8 or fewer exons. This truncation ensures a focused and clear analysis of the majority of CNV calls.}
\end{figure}

\section{Model Variables Analysis}

The feature variables play a vital role in machine learning algorithms. They provide the necessary information for the algorithm to learn and make predictions. The quality and relevance of the feature variables greatly impact the accuracy and performance of the model. By choosing the right feature variables, we can improve the predictive power of our machine learning models.

To enhance the efficiency of our model for detecting Copy Number Variants (CNVs), \st{we automatically incorporate various metrics that impact CNV detection. In this section,} we will analyze how these different variables influence model performance to achieve a model that optimally balances accuracy and simplicity.

%\begin{itemize}
%\item \textbf{Chromosome (chr)}: The chromosome on which the CNV is located.
%\item \textbf{CNV Type (type)}: Indicates whether the CNV is a deletion or duplication.
%\item \textbf{Number of Exons Included in the CNV (numb\_exons)}: The count of exons within the CNV.
%\item \textbf{DECoN Call (decon)}: Indicates if a DECoN call overlaps the CNV.
%\item \textbf{GATK gCNV Call (gatk)}: Indicates if a GATK gCNV call overlaps the CNV.
%\item \textbf{Grapes Call (grapes)}: Indicates if a Grapes call overlaps the CNV.
%\item \textbf{GC Content (gc\_content)}: The percentage of guanine and cytosine nucleotides within the CNV region.
%\item \textbf{Mappability (mappability)}: A measure of how uniquely the CNV region can be mapped to the reference genome.
%\item \textbf{Length of the CNV (cnv\_length)}: The total length of the CNV.
%\item \textbf{Gene (gene)}: The gene(s) overlapping with the CNV.
%\item \textbf{DECoN Quality (decon\_qual)}: The quality score assigned by DECoN to the CNV call, available only if DECoN made a call overlapping the CNV.
%\item \textbf{GATK gCNV Quality (gatk\_qual)}: The quality score assigned by GATK gCNV to the CNV call, available only if GATK made a call overlapping the CNV.
%\item \textbf{Grapes Quality (grapes\_qual)}: The quality score assigned by Grapes to the CNV call, available only if Grapes made a call overlapping the CNV.
%\item \textbf{Sample Correlation Against the Cohort (sample\_correlation)}: The mean correlation value of the sample exons' mean read depth against the read depth of the cohort samples for the corresponding exon. (Section \ref{mean_read_depth}).
%\end{itemize}

%The target variable for prediction is:
%\begin{itemize}
%\item \textbf{True Positive CNV Call (true\_positive)}: Indicates whether the CNV overlaps an in-silico CNV, thereby determining if it is a True Positive call (True) or not (False).
%\end{itemize}

%These 
Variables fall into three main categories: sample quality, CNV quality, and CNV genomic context. Each provides crucial information to the model, aiding in the accurate prediction of whether a CNV call is a True Positive or a False Positive.

In the following analysis, we will explore the relationships between these variables and their impact on the predictive accuracy of the model.

\subsection{CNV quality variables}
The CNV quality variables encompass all metrics related to CNV calls and their respective accuracies, including DECoN call, GATK gCNV call, Grapes call, DECoN quality, GATK gCNV quality, and Grapes quality.

\begin{wrapfigure}{r}{0.5\textwidth}    \centering
    \includegraphics[width=0.48\textwidth]{imatges/venn_diagram_cropped.png}
    \caption{\label{fig:venn_diagram} Venn diagram illustrating the overlap between calls made by the CNV detection algorithms: DECoN, GATK, and Grapes. Each section of the diagram is annotated with the number of true positive (TP) and false positive (FP) CNV calls. The diagram visualizes the intersections of the algorithms' calls and highlights both unique and overlapping CNV identifications.}
\end{wrapfigure}

The performance of individual CNV detection algorithms has been assessed in Section \ref{standalone_algorithms}. Here, we evaluate whether overlapping calls from different algorithms enhance the confidence in CNV detection.

Figure \ref{fig:venn_diagram} presents a Venn diagram showing the overlap of CNV calls made by DECoN, GATK, and Grapes. The central region, where all three algorithms concur, exhibits the highest number of true positive calls (837) and a relatively low number of false positive calls (54). This indicates a high level of confidence in CNV calls identified by all three algorithms.

Examining the regions where two algorithms agree, there is a noticeable increase in the false discovery rate compared to the region of complete overlap. Notably, combinations involving DECoN with either GATK or Grapes demonstrate better performance compared to the combination of GATK and Grapes. Calls made by single algorithms, despite identifying some true positives, generally exhibit a high false positive rate, suggesting lower reliability in these cases.



The results suggest that the overlap of algorithm calls is a critical factor in determining the reliability of CNV detection. Consequently, these overlapping calls are expected to significantly influence the machine learning model we will develop, given their demonstrated high reliability when all three algorithms agree.
\begin{wrapfigure}{r}{0.65\textwidth}    \centering
    \includegraphics[width=0.65\textwidth]{imatges/alg_qualities.png}
    \caption{\label{fig:cnvquals} Distribution of CNV quality scores for DECoN, GATK, and Grapes algorithms against the whether if the CNV is a True Positive or an artifact. True positive CNVs are shown in blue, while false positive CNVs are shown in red. The quality scores are indicative of the confidence in the CNV call, with higher scores correlating with true positive CNVs.}
\end{wrapfigure}

Next, we examine how the quality scores of the algorithm calls relate to the likelihood of a CNV being a true positive or a false positive.
Figure \ref{fig:cnvquals} shows the distribution of CNV call quality scores for each algorithm against the predicted variable (whether the CNV is a real CNV or an artifact). It is evident that for each algorithm, false positive CNVs tend to accumulate at lower quality scores, whereas true positive CNVs are more prevalent at higher quality scores. This observation suggests that the quality score is a valuable feature for the model to distinguish between true positive and false positive CNVs.

These findings underscore the importance of quality scores in improving the accuracy of CNV detection. By incorporating these quality variables into our machine learning model, we can enhance its ability to correctly classify CNVs, thereby reducing the false discovery rate.

\subsection{CNV Genomic Context Variables}

The genomic context of CNVs is described by several variables, including chromosome, CNV type, number of exons included in the CNV, GC content, mappability, CNV length, and gene association. We will now examine the distribution of true positive and false positive CNVs across these variables.


\subsubsection{Genes}
Figure \ref{fig:genes_variable} illustrates the top 10 genes with the highest number of false positive CNVs alongside the top 10 genes with the highest number of true positive CNVs. The random insertion of in silico CNVs often leads to a higher accumulation of true positive CNVs in larger genes. However, some genes also show a tendency to accumulate false positive calls, making them significant variables to consider in our model.


\begin{figure}[htb]
\includegraphics[width=15 cm]
{imatges/genes_variable.png}
    \caption{\label{fig:genes_variable} The figure on the left displays the top 10 genes with the highest number of false positive CNVs, along with the true positive CNVs found in these genes. The figure on the right shows the top 10 genes with the highest number of true positive CNVs, along with the false positive CNVs identified in these genes.}
\end{figure}

\subsubsection{Chromosome}
\begin{wrapfigure}{r}{0.65\textwidth}    \centering
    \includegraphics[width=0.65\textwidth]{imatges/chr_variable.png}
    \caption{\label{fig:chr} Distribution of CNVs across chromosomes, highlighting the chromosomes with higher accumulations of false positives.}
\end{wrapfigure}
Figure \ref{fig:chr} illustrates the chromosomes with higher accumulations of false positive CNVs. Notably, chromosomes 2, 6, 7, and X exhibit elevated frequencies of false CNV calls. This pattern is partly attributed to the presence of genes on these chromosomes that are prone to generating false positives. For instance, chromosome 2 contains genes such as TTN and SOS1, chromosome 6 includes TRDN, and chromosome 7 features CACNA2D1 and AKAP9, all of which are associated with higher false positive rates.

Chromosome X, a sex chromosome with differing copy numbers between males (one copy) and females (two copies), introduces additional challenges in CNV detection. The variable copy number can complicate accurate CNV assessment, leading to a higher incidence of false positive calls.

To better address these issues, we propose incorporating a new categorical variable to distinguish between autosomal and sex chromosomes (chrX and chrY). This addition will help in understanding and mitigating the specific challenges associated with CNV detection on sex chromosomes, thereby improving the overall accuracy of CNV identification.

\subsubsection{CNV type}
\begin{wrapfigure}{r}{0.55\textwidth}    \centering
    \includegraphics[width=0.55\textwidth]{imatges/cnv_type_variable.png}
    \caption{\label{fig:cnv_type}Distribution of CNV types in the dataset, illustrating the prevalence of deletions versus duplications among false positive and true positive calls. }
\end{wrapfigure} 

Previous studies have suggested that duplications are generally more challenging to detect compared to deletions. For instance, some references highlight the difficulties associated with detecting duplications in CNV detection algorithms due to subtler signal changes and increased background noise (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8699073/,https://www.nature.com/articles/s41431-020-0675-z).


However, as illustrated in Figure \ref{fig:cnv_type}, our analysis reveals that the number of false positive CNV calls is approximately equivalent for both duplications and deletions. In addition, the number of True positive CNV calls is consistent with our experimental design, where we introduced two duplications and two deletions per sample in silico. Consequently, the algorithms detected these CNVs in roughly equal proportions.

Given these findings, it appears that CNV type (duplication versus deletion) does not significantly influence the accuracy of detection in the context of our dataset. Therefore, for the model constructed using the SUDD147 panel, it may be reasonable to exclude the CNV type variable from consideration, as its impact on the detection accuracy does not appear to be substantial.
\subsubsection{Number of exons and CNV length}
\textbf{Buscar una altra figura que descrigui millor les variables i permeti veure si hi ha diferencies amb la variable predictora!}\\
The number of exons and CNV length are two key variables that measure the size of the CNV, albeit in different ways. These variables are highly correlated, with a Pearson correlation coefficient of 0.738. This high correlation suggests that they may convey similar information.

However, as shown in Figure \ref{fig:exons_length}, the distribution of true positive and false positive calls against these two variables appears to be quite similar. This similarity indicates that these variables might not provide significant discriminatory power for the model, as they do not distinguish well between true positive and false positive CNV calls.

Given this observation, we will conduct a further analysis to determine the impact of these variables on the model's performance. If it is found that these variables do not enhance the predictive accuracy of the model, we may consider removing them to simplify the final model.

\begin{figure}[htb]
\includegraphics[width=15 cm]{imatges/boxplots.png}
    \caption{\label{fig:exons_length} Boxplots representing the distribution of true positive calls and false positive calls against the variables number of exons and cnv length. }
\end{figure}

\subsubsection{GC Content}

Regions of the genome where the GC content significantly deviates from 50\% tend to experience more misalignments, leading to a less uniform distribution of reads. As a result, these regions are prone to higher rates of false positive CNV calls. This phenomenon is due to the challenges in sequencing and alignment accuracy in regions with extreme GC content, which complicates the detection of true CNVs.

In Figure\ref{fig:gc_content}, we analyze the distribution of GC content for true positive and false positive CNV calls. The histogram and corresponding density plots illustrate that false positive CNV calls are more frequent in regions where the GC content is either much lower or much higher than 50\%. Conversely, true positive CNV calls tend to cluster around the 50\% GC content mark. Therefore, accounting for GC content in the model could help reduce the rate of false positives and improve overall detection accuracy.
\begin{figure}[htb]
\includegraphics[width=15 cm]{imatges/gc_content.png}
    \caption{\label{fig:gc_content} GC content distribution differences between true positive and false positive CNV calls. The vertical dashed line indicates the 50\% GC content mark.}
\end{figure}

Extra: maybe considering just to label (1/0) these CNVs that its GC content is lower than 30\% or higher than 70\% could help to improve the model (thing to try)

\subsubsection{Mappability}
Mappability refers to the ability to uniquely map sequencing reads to a reference genome, which can impact the detection and accuracy of copy number variations (CNVs). To evaluate whether mappability plays a significant role in distinguishing between true positive and false positive CNV calls, we analyzed the distribution of these calls across varying mappability values.

As illustrated in Figure \ref{fig:mappability}, the density distributions of true positive and false positive CNVs relative to the mappability values of their corresponding genomic regions are highly similar. Both types of CNV calls exhibit a significant peak at a mappability value of 1.0, indicating regions with perfect mappability. However, there are no substantial differences in the distributions at lower mappability values.

This similarity suggests that mappability does not provide a distinguishing factor between true positive and false positive CNVs. Therefore, incorporating mappability into our model does not enhance its ability to accurately differentiate between genuine CNVs and artifacts. Consequently, mappability can likely be excluded as a predictive variable in our model without sacrificing accuracy.

\begin{figure}[htb]
\centering
\includegraphics[width=15 cm]{imatges/mappability.png}
\caption{\label{fig:mappability} Distribution of mappability values for true positive and false positive CNVs. The density plots indicate that both true positives and false positives are similarly distributed across mappability values, with a notable peak at a mappability value of 1.}
\end{figure}

\subsection{Quality Samples Variables}

In this group, we are only using one variable that is describing the quality of the sample and it is the sample correlation.

we analyze how the correlation values affect the model's ability to differentiate between true positive and false positive CNV  detections.

To visualize this, we generated a density plot, as shown in Figure \ref{fig:correlation_samples}.
\begin{figure}[htb]
\includegraphics[width=10 cm]{imatges/correlation.png}
\caption{\label{fig:correlation_samples}Density plot showing how the correlation of samples affects the number of true positive and false positive CNVs.}
\end{figure}
The density plot displays the distribution of correlation values for true positive and false positive CNVs. We observe that the correlation values of the samples range between 0.70 and 0.91. We should take into account that four CNVs were introduced in each sample, so a higher number of True positive CNVs in the distribution is an indicative of a higher number of samples between these correlation range. By comparing the distribution of CNVs between true positive and false positive detections, we note that at lower correlation values (<0.85), there is a tendency to obtain more false positive CNVs than true positive CNVs. However, at higher correlation values, this trend reverses, resulting in a higher number of true positive CNVs compared to false positive CNVs.

This observation demonstrates that lower quality samples tend to have a higher rate of false positive CNVs, whereas higher quality samples are associated with a lower rate of false positive CNVs.

\section{Model Selection}



To ensure the best model is selected, we performed a rigorous evaluation using both random forest and XGBoost by first finding the best hyperparameters for both models. Then, to mitigate the risk of overfitting and ensure that our model generalizes well to unseed data, we employed k-fold cross-validation. This technique divides the data into k subsets and trains the model k times, each time using a different subset as the validation set while the remaining k-1 subsets are used for training.

As presented in Table \ref{table:model_results} the evaluation metrics indicate that XGBoost consistently outperforms Random Forest across all considered metrics, including accuracy, precision, recall, and F1 score. The superior performance of XGBoost can be attributed to its advanced capabilities in handling complex patterns within the data and its robustness against overfitting, especially when dealing with high-dimensional datasets.

Based on these findings, XGBoost is selected as the primary machine learning algorithm for this project. Its ability to deliver higher predictive accuracy and its overall better performance metrics make it the most suitable choice for our objectives.


\begin{table}[htb]
\centering
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{ | r | c | c | c |  l | }
 \hline
    Model & Accuracy & Specificity & Recall & F1 Score\\
    Random Forest & 0.9515 & 0.9693 & 0.9182 & 0.9294\\
    XGBoost & 0.9582 & 0.9693 & 0.9231 & 0.9389\\
\hline
  \end{tabular}
  \end{adjustbox}
\caption{Metrics to evaluate Random Forest and XGBoost model performance.}
\label{table:model_results} 
\end{table}

\section{Feature Selection}


First, we train an XGBoost model on the entire dataset to obtain an initial set of feature importance scores and model metrics. The feature importance scores indicate the relative importance of each feature in predicting the target variable. Features are then ranked based on these importance scores, and the feature that contributes the least to the model is eliminated. This process is iterative: we repeatedly remove the least contributing feature, train a new model without this feature, and compare the model parameters to evaluate the impact of each feature removal on the model's performance.

In Figure \ref{fig:feature_remove}, the model's metrics remain stable when the first four features are removed. From this point onward, the metrics start to decrease, indicating that the removal of these initial features (Chromosome, Mappability, Gene, and CNV type) does not significantly affect the model's predictive effectiveness. This suggests that these features can be excluded without compromising the model's performance.

\begin{figure}[htb]
\includegraphics[width=15 cm]{imatges/feature_remove.png}
\caption{\label{fig:feature_remove}Model metrics with the associated features eliminated in each round to perform feature selection.}
\end{figure}

As previously observed, Mappability and CNV type do not provide substantial information to the model, as their distributions are similar between true positives and false positives. However, the features Gene and Chromosome exhibit different distributions when compared to the predicted feature, suggesting that their removal does not harm the model due to their generalized nature.

Chromosome and Gene are broad variables, and their different distributions likely stem from inherent properties that are already included in the model (GC content, CNV length, number of exons) that do not contribute significantly to distinguishing between true positive and false positive CNVs. Consequently, their exclusion does not reduce the model's ability to make accurate predictions.

\section{Model Evaluation}



The final model includes the following variables: number of exons, CNV length, DECoN, Grapes, GATK, DECoN quality call, Grapes quality call, GATK quality call and sample correlation. The performance metrics, as depicted in Figure \ref{fig:conf_matrix_final}, demostrate the effectiveness of these features in predicting CNVs.

\begin{figure}[htb]
\centering
\includegraphics[width=7 cm]
{imatges/confusion_matrix_final.png}
\caption{\label{fig:conf_matrix_final} Confussion matrix and metrics for the final model.}
\end{figure}

In our specific context, recall is of paramount importance. 

%Our primary goal is to identify all possible CNVs, even if this results in a higher rate of false positives.

%\begin{wrapfigure}{r}{0.55\textwidth}    \centering
%    \includegraphics[width=0.55\textwidth]{imatges/CNV_call_process.png}\caption{\label{fig:cnv_validation_process}Validation process over the calls made by the CNV detection pipeline.}
%\end{wrapfigure} 
% This strategy is justified because we plan to apply orthogonal validation techniques to confirm the presence of CNVs identified by our model \ref{fig:cnv_validation_process}. False positives generated by the model will undergo further validation, minimizing the risk of missing true CNVs during the orthogonal validation process. Therefore, maximizing recall is crucial to ensure that as many potential CNVs as possible are flagged for further validation.

To enhance recall, we adjusted the decision threshold for the XGBoost model. The standard classification threshold of 0.5 means that a CNV is classified as positive only if more than half of the trees in the ensemble agree. By lowering this threshold, we increase the sensitivity of the model, making it more likely to predict positive CNVs and thereby improving recall. However, this adjustment inevitably leads to an increase in false positives. These false positives will be subsequently addressed through our orthogonal validation process, ensuring that the overall reliability of CNV detection remains high.

Figure \ref{fig:thresholds} illustrates how different model metrics respond to varying decision thresholds for considering a CNV a true positive instance. As shown, the decision threshold increases the recall of the model, meaning it can identify a higher number of true CNV instances. However, this comes with a trade-off: the precision decreases as more non-CNV instances are misclassified as true CNVs.

\begin{figure}[htb]
\centering
\includegraphics[width=13 cm]{imatges/xgboost_thresholds.png}
\caption{\label{fig:thresholds} Impact of varying decision thresholds on XGBoost model metrics.}
\end{figure}

A reliable decision threshold could be between 0.2 and 0.3, where the model achieves a recall of 0.9519 to 0.9711 and a precision of 0.9252 to 0.8938, respectively. This range represents a balance between high sensitivity and acceptable precision, ensuring that almost all CNVs are detected while minimizing the economic and labor costs associated with validating CNVs through MLPA (Multiplex Ligation-dependent Probe Amplification).

By selecting a threshold within this range, we prioritize the detection of true CNVs, which is crucial given the potential consequences of missing true variants. Although this approach increases the number of false positives, the subsequent orthogonal validation process will filter out these inaccuracies, preserving the overall reliability and effectiveness of our CNV detection pipeline.


\section{Validation of Real CNVs}

\section{Discussion}

\hl{Comparativa dels metodes sols versus la teva proposta. Comenta si has assolit els objectius}



\chapter{CONCLUSION}

\hl{Par 1.Resum motivacio i objectius. Par 2. Resum de la metodologia. Par 3. resum de l'experimentacio i resultats obtinguts. Par 4. Treball futur. }


\begin{table}[htb]
\centering
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{ | r | l | }
 \hline
    Feature & Importance\\
\hline
Grapes  & 0.2304 \\
GATK & 0.2216\\
GATK Q & 0.1393\\
DECoN & 0.0696 \\
Grapes Q & 0.0641\\
DECoN Q & 0.0616\\
Number of exons & 0.0344\\
Sample correlation & 0.0309\\
CNV length & 0.02534\\
GC content & 0.0222\\
CNV type & 0.02

  \hline
  \end{tabular}
  \end{adjustbox}
\caption{Labels assigned to the Overlapped CNV containing if the CNV was detected by the different algorithm and if it overlaps a inserted in silico CNV.}
\label{table:CNV_labelled} 
\end{table}
\section{Model Evaluation}

The dataset used for


\appendix
\section{Appendix}


\begin{sidewaystable}[ht]
\centering
\scriptsize
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
Start & End & Chr & Length & Type & Nº exons & DECoN & GATK & GRAPES & GC cont & Mapp & Gene & DECoN Q & GATK Q & GRAPES Q & Corr & TP \\
\hline
154677193 & 154677632 & chr7 & 439 & DUP & 1 & 1 & 1 & 1 & 58,41 & 1 & DPP6 & 18,7 & 83,12 & 0,91 & 0,8996 & True \\
\hline
69902621 & 69921607 & chr10 & 18986 & DEL & 6 & 1 & 1 & 1 & 40,49 & 0,367 & MYPN & 74.5 & 1226.05 & 0.957 & 0,8996 & TRUE \\
\hline
78390784 & 78391003 & chr1 & 219 & DEL & 1 & 1 & 0 & 0 & 28,64 & 1 & NEXN & 2,99 & - & - & 0,814 & FALSE \\
\hline
123576139 & 123580898 & chr6 & 4759 & DUP & 3 & 1 & 0 & 0 & 35,17 & 0,375 & TRDN & 3,97 & - & - & 0,802 & FALSE \\
\hline
\end{tabular}
\caption{Features provided as input to the model. Detection by DECoN, GATK, and GRAPES is indicated by 0 (not detected) or 1 (detected). Quality scores for these calls are indicated by 'Q' after the algorithm name. 'TP' (True Positive) indicates whether the variant was inserted in-silico (True) or is a false positive call (False).}
\label{tab:Model_input}
\end{sidewaystable}

% \subsubsection{Technical biases and artifacts}

% One of the primary challenges in CNV detection is the presence of technical biases and artifacts in sequencing data. These biases and artifacts stem from various sources during the sequencing process, leading to inaccuracies in read depth measurements, which are crucial for detecting CNVs. The following factors contribute significantly to these technical challenges:

% Uneven Coverage
% Uneven coverage is a common issue in targeted sequencing, where the depth of sequencing can vary significantly across different regions of the genome. This variability can be caused by several factors, including differences in the efficiency of capturing target regions, PCR amplification biases, and stochastic variations in sequencing. Regions with low coverage may be misinterpreted as deletions, while regions with unexpectedly high coverage might be mistaken for duplications. To address uneven coverage, algorithms often employ normalization techniques that adjust read counts based on the expected coverage distribution, using either control samples or statistical models to predict and correct for these variations.


% Uneven Coverage
% Uneven coverage is a common issue in targeted sequencing, where the depth of sequencing can vary significantly across different regions of the genome. This variability can be caused by several factors, including differences in the efficiency of capturing target regions, PCR amplification biases, and stochastic variations in sequencing. Regions with low coverage may be misinterpreted as deletions, while regions with unexpectedly high coverage might be mistaken for duplications. To address uneven coverage, algorithms often employ normalization techniques that adjust read counts based on the expected coverage distribution, using either control samples or statistical models to predict and correct for these variations.
% Aquest és un gran treball que bla, bla, bla,\ldots

% Com s'explicarà al Capítol~\illustrating{cap:prelim} (això és un exemple de illustrating how deleerència),\ldots

% Això és un exemple de citació d'un llibre~\cite{Coleman1974}, un article científic~\cite{Ruiz2008} i una illustrating how deleerència a una web~\cite{Halcon}.

% Exemple de taula:
% \begin{table}[htb]
% \centering
% \begin{tabular}{ | r | c | c | l | }
%  \hline
%   Any & Matriculats & Aprovats & Percentatge\\
% \hline
%  2019  & 65 & 47 & 72.3\%\\
%  2020  & 69 & 48 & 69.6\%\\
%  2021  & 75 & 58 & 77.3\%\\
%   \hline
%   \end{tabular}
% \caption{Aquí és on s'ha de posar el peu de taula.}
% \label{taula:taulaexemple} 
% \end{table}

% Exemple de figura:
% \begin{figure}[htb]
% \centering
% \includegraphics[width=8 cm]{imatges/logo_eps.png}
% \caption{\label{fig:logo} Logotip de l'Escola Politècnica Superior.}
% \end{figure}

% Exemple de fòrmula:
% \begin{equation}
% H(X) = -\sum_{i=1}^{N}p_s(x_i) \log \left( p_s(x_i) \right).
% \label{equ:entropia}
% \end{equation}


% També es pot fer illustrating how deleerència en el text a les taules (p.ex. veure la Taula~\ref{taula:taulaexemple}), a les figures (p.ex. veure la Figura~\ref{fig:logo}) o a les fòrmules (p.ex. veure Equació~\ref{equ:entropia}).

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc congue mattis tellus, in rhoncus nisl laoreet vel. Sed nulla libero, tincidunt id ligula congue, hendrerit maximus mi. Morbi nec metus in urna imperdiet mattis pretium a libero. Fusce est mauris, convallis id facilisis faucibus, consequat aliquet eros. Vivamus et dui pulvinar, rutrum velit at, volutpat tellus. Nulla vehicula ullamcorper justo, blandit interdum leo sagittis quis. Quisque convallis vel ante ac rutrum. Morbi et varius sem, sed tristique elit. Vestibulum aliquam facilisis pellentesque. Suspendisse consequat commodo eros, sit amet tincidunt sapien semper in. Nunc ut magna ac quam tempor malesuada et at ex. Donec mattis mauris ante, id condimentum elit dapibus at.

% Curabitur ut sodales sapien. Etiam eget ultrices risus, in dignissim nunc. Quisque quis tortor in nunc posuere lacinia ut sed dui. Praesent ut sollicitudin diam, ut mattis magna. Morbi porttitor fermentum magna a pharetra. Nullam at magna diam. Suspendisse vehicula tellus eget ligula aliquam semper. Integer sed ullamcorper felis, ac imperdiet elit. Praesent eu suscipit ligula, sit amet vulputate erat. Etiam eget tempor est, vitae aliquet tortor. Nam efficitur tristique ligula. Aliquam blandit leo non ante suscipit, vitae mattis diam rhoncus. Ut ac dui sit amet dui venenatis suscipit.

% Nunc sollicitudin hendrerit risus, quis ultricies orci elementum non. Aliquam erat volutpat. Mauris neque turpis, molestie in tellus id, pharetra gravida mi. Suspendisse potenti. Donec aliquam dolor eu pellentesque auctor. Proin eget sapien ut tellus maximus lacinia. Praesent blandit pretium mi, suscipit sollicitudin eros iaculis in. Nunc a justo sit amet mauris auctor posuere sit amet vel erat. Etiam in maximus nisi. Pellentesque blandit pharetra lectus nec efficitur. Praesent tristique vel arcu id bibendum. In eget eros fringilla magna hendrerit facilisis ac vitae urna. Donec malesuada fermentum dictum. Pellentesque aliquet tortor vitae suscipit tempus. Phasellus ornare risus mi, vel placerat justo efficitur eu. Phasellus quis tincidunt enim.

% Etiam a elementum lorem. Integer ac lectus hendrerit, venenatis ante vitae, accumsan eros. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Curabitur non varius dolor. Donec suscipit metus vitae ultrices sagittis. Praesent ac dapibus justo, vel mollis sapien. Pellentesque at iaculis neque. Donec ac tellus orci. Pellentesque eleifend fringilla massa, in lobortis nibh finibus in. Morbi ut neque vitae est congue tempor efficitur imperdiet dolor. Pellentesque nec nibh nec nibh fringilla laoreet. Duis fermentum ornare sollicitudin. Maecenas finibus tincidunt justo commodo commodo. Suspendisse venenatis odio dignissim auctor elementum. Duis non mauris orci.

% \chapter{Estat de l'art}
% \label{cap:estat}

% \section{Secció}

% \subsection{Subsecció}

% \chapter{Preliminars}
% \label{cap:prelim}

% \chapter{Planificació i Metodologia}
% \label{cap:plan}

% \chapter{Contribució Metodològica}
% \label{cap:contrib}

% \chapter{Resultats}
% \label{cap:result}

% \chapter{Conclusions i treball futur}
% \label{cap:concl}

% \backmatter

% %\appendix

% %\include{Appendix1}

% \bibliographystyle{ThesisStyleBreakable}
% \bibliography{biblio}

% %\printnomenclature

\end{document}
